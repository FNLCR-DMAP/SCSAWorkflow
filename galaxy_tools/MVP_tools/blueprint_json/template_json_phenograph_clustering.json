{
  "rid": "ri.vector.main.template.ef9d46bf-2700-4304-a721-883c7f0676af",
  "title": "Phenograph Clustering [SPAC] [DMAP]",
  "description": "Calculate automatic phenotypes using PhenoGraph. The unsupervised clusters will be stored in annotation: \"phenograph\" by default in the analysis. \\\nPlease refer to [DUET Documentation](https://nidap.nih.gov/shares/links/6xtboqycghxu4) and [GitHub Documentation](https://fnlcr-dmap.github.io/SCSAWorkflow/spac.html#spac.transformations.phenograph_clustering) for further information.",
  "createdBy": "473c74f1-6764-4d6c-87e8-4a56c2b2f5a0",
  "createdAt": "2025-02-24T15:29:25.18969084Z",
  "commitMessage": "",
  "status": "RELEASED",
  "inputDatasets": [
    {
      "key": "Upstream_Analysis",
      "displayName": "Upstream Analysis",
      "description": "Link to prior processed dataset in the analysis.",
      "paramGroup": null,
      "anchorDataset": null,
      "dataType": "PYTHON_TRANSFORM_INPUT",
      "tags": []
    }
  ],
  "parameters": [
    {
      "key": "Run_on_HPC",
      "displayName": "Run on HPC",
      "description": "If toggled on, this template will launch a computational task on HPC cluster with resource specified in the \"HPC Configuration\" parameters group. The computational result will be available one the HPC task is completed.",
      "paramType": "BOOLEAN",
      "paramGroup": null,
      "paramValues": null,
      "defaultValue": "False",
      "condition": null,
      "content": null,
      "objectPropertyReference": null
    },
    {
      "key": "Table_to_Process",
      "displayName": "Table to Process",
      "description": "Source table to perform the computation. The default value \"Original\" will use the raw dataset.",
      "paramType": "STRING",
      "paramGroup": null,
      "paramValues": null,
      "defaultValue": "Original",
      "condition": null,
      "content": null,
      "objectPropertyReference": null
    },
    {
      "key": "K_Nearest_Neighbors",
      "displayName": "K-Nearest Neighbors",
      "description": "The number of nearest neighbors to be used in creating the features neighborhood graph.",
      "paramType": "INTEGER",
      "paramMin": "1",
      "paramGroup": null,
      "paramValues": null,
      "defaultValue": "30",
      "condition": null,
      "content": null,
      "objectPropertyReference": null
    },
    {
      "key": "Seed",
      "displayName": "Seed",
      "description": "Random seed for reproducibility.",
      "paramType": "INTEGER",
      "paramMin": "1",
      "paramGroup": null,
      "paramValues": null,
      "defaultValue": "42",
      "condition": null,
      "content": null,
      "objectPropertyReference": null
    },
    {
      "key": "Resolution_Parameter",
      "displayName": "Resolution Parameter",
      "description": "The resolution parameter (>0) adjusts the level of granularity in identifying clusters within a dataset, with higher values promoting the detection of a larger number of clusters (e.g., more distinct clusters), while lower values emphasize a smaller number of clusters (e.g., more inclusive clusters).",
      "paramType": "NUMBER",
      "paramMin": "0",
      "paramGroup": null,
      "paramValues": null,
      "defaultValue": "1",
      "condition": null,
      "content": null,
      "objectPropertyReference": null
    },
    {
      "key": "Output_Annotation_Name",
      "displayName": "Output Annotation Name",
      "description": "The output annotation name from Phenograph clustering to be added to the analysis. Default is \"phenograph\".",
      "paramType": "STRING",
      "paramGroup": null,
      "paramValues": null,
      "defaultValue": "phenograph",
      "condition": null,
      "content": null,
      "objectPropertyReference": null
    },
    {
      "key": "Number_of_Iterations",
      "displayName": "Number of Iterations",
      "description": "Number of iterations to run the Leiden graph clustering algorithm. If the number of iterations is negative, the Leiden algorithm is run until an iteration in which there was no improvement. Default is 100.",
      "paramType": "Positive integer",
      "paramGroup": null,
      "paramValues": null,
      "defaultValue": "100",
      "condition": null,
      "content": null,
      "objectPropertyReference": null
    },
    {
      "key": "Profiling",
      "displayName": "Profiling",
      "description": "Available on HPC only. If on, the template will run through all the resolutions defined in the resolution parameters only in GPU mode.",
      "paramType": "BOOLEAN",
      "paramGroup": "Resolution Profiling",
      "paramValues": null,
      "defaultValue": "False",
      "condition": null,
      "content": null,
      "objectPropertyReference": null
    },
    {
      "key": "Resolution_List",
      "displayName": "Resolution List",
      "description": "List of resolutions used when the Profiling is True.",
      "paramType": "LIST",
      "paramGroup": "Resolution Profiling",
      "paramValues": null,
      "defaultValue": "[]",
      "condition": null,
      "content": null,
      "objectPropertyReference": null
    },
    {
      "key": "HPC_Compute_Mode",
      "displayName": "HPC Compute Mode",
      "description": "The compute mode for this submission. Available options are CPU and GPU, which run the compute on CPU or GPU, respectively. Please remind that if Profiling option is true, the default mode is set as GPU",
      "paramType": "SELECT",
      "paramGroup": "HPC Configurations",
      "paramValues": [
        "CPU",
        "GPU"
      ],
      "defaultValue": "CPU",
      "condition": null,
      "content": null,
      "objectPropertyReference": null
    },
    {
      "key": "Batch_Mode",
      "displayName": "Batch Mode",
      "description": "If set to True, this HPC run will launch in batch mode showing the template status as successful once the job is submitted to the HPC cluster. the results will be written after the HPC job completes. Avoid submitting twice before completion to prevent race conditions.",
      "paramType": "BOOLEAN",
      "paramGroup": "HPC Configurations",
      "paramValues": null,
      "defaultValue": "False",
      "condition": null,
      "content": null,
      "objectPropertyReference": null
    },
    {
      "key": "Partition",
      "displayName": "Partition",
      "description": "Biowulf nodes are grouped into partitions. A partition can be specified when submitting a job. Please refer to https://hpc.nih.gov/docs/userguide.html#Partitions for more details",
      "paramType": "SELECT",
      "paramGroup": "HPC Configurations",
      "paramValues": [
        "quick",
        "norm",
        "gpu",
        "largemem"
      ],
      "defaultValue": "quick",
      "condition": null,
      "content": null,
      "objectPropertyReference": null
    },
    {
      "key": "Number_of_CPUs",
      "displayName": "Number of CPUs",
      "description": "Number of CPUs requested for this HPC submission",
      "paramType": "Positive integer",
      "paramGroup": "HPC Configurations",
      "paramValues": null,
      "defaultValue": "2",
      "condition": null,
      "content": null,
      "objectPropertyReference": null
    },
    {
      "key": "Memory_GB",
      "displayName": "Memory, GB",
      "description": "Amount of memory in gigabytes requested for this HPC submission",
      "paramType": "Positive integer",
      "paramGroup": "HPC Configurations",
      "paramValues": null,
      "defaultValue": "10",
      "condition": null,
      "content": null,
      "objectPropertyReference": null
    },
    {
      "key": "Request_Time",
      "displayName": "Request Time",
      "description": "Amount of time requested for this HPC submission. Please provide the time in the format of hh:mm:ss. For example, 2 hour 30 minute job would be 02:30:00. Please remind that different partition has different time limit, please refer to https://hpc.nih.gov/docs/userguide.html#Partitions for further details.",
      "paramType": "STRING",
      "paramGroup": "HPC Configurations",
      "paramValues": null,
      "defaultValue": "00:20:00",
      "condition": null,
      "content": null,
      "objectPropertyReference": null
    }
  ],
  "columns": [],
  "orderedMustacheKeys": [
    "Upstream_Analysis",
    "Run_on_HPC",
    "Table_to_Process",
    "K_Nearest_Neighbors",
    "Seed",
    "Resolution_Parameter",
    "Output_Annotation_Name",
    "Number_of_Iterations",
    "Profiling",
    "Resolution_List",
    "HPC_Compute_Mode",
    "Batch_Mode",
    "Partition",
    "Number_of_CPUs",
    "Memory_GB",
    "Request_Time"
  ],
  "contents": {
    "type": "code",
    "code": {
      "codeLanguage": "PYTHON",
      "codeTemplate": "def Phenograph_Clustering({{{Upstream_Analysis}}}):\n\n    ## --------- ##\n    ## Libraries ##\n    ## --------- ##\n    import pickle\n    from pyspark import SparkContext\n    from spac.transformations import phenograph_clustering\n    from hpc_connector_addons.main import hpc_direct_launch\n    from hpc_connector_addons.hpc_request_utils import write_file_to_dataset_dmap\n\n    ## -------------------------------- ##\n    ## User-Defined Template Parameters ##\n    ## -------------------------------- ##\n    profiling = {{{Profiling}}}\n    run_on_HPC = {{{Run_on_HPC}}}\n    hpc_partition = \"{{{Partition}}}\"\n    hpc_n_cpus = {{{Number_of_CPUs}}}\n    hpc_mem = \"{{{Memory_GB}}}\"\n    hpc_time = \"{{{Request_Time}}}\"\n    hpc_gpu = \"a100\"\n    hpc_gpu_num = 1\n    hpc_mode = \"{{{HPC_Compute_Mode}}}\"\n    batch_mode = {{{Batch_Mode}}}\n\n    if run_on_HPC:\n        template_code = \"spac_phenograph\"\n        input_file_name = \"transform_output.pickle\"\n\n        hpc_config = {\n            \"cpu\": hpc_n_cpus,\n            \"partition\": hpc_partition,\n            \"time\": hpc_time,\n            \"mem\": hpc_mem,\n            \"gpu\": hpc_gpu,\n            \"gpu_num\": hpc_gpu_num\n        }\n\n        if profiling:\n            hpc_mode = \"GPU\"\n\n        upstream_node = {{{Upstream_Analysis}}}\n\n        transform_output = Transforms.get_output()\n\n        Current_SparkContext = SparkContext.getOrCreate()\n\n        try:\n            monitor_result = hpc_direct_launch(\n                upstream_node=upstream_node,\n                transform_output=transform_output,\n                mode=hpc_mode,\n                template=template_code,\n                hpc_config=hpc_config,\n                input_file=input_file_name,\n                batch_mode=batch_mode,\n                track_current=False,\n                test_flag=False\n            )\n        except:\n            raise ValueError(\"HPC job had encountered an error. Please check the log for further information.\")\n            return None\n        if batch_mode:\n            return None\n        if monitor_result[\"has_file\"]:\n            adata = pickle.loads(monitor_result[\"data\"])\n            print(\"\\n\\n\\n#####################################\")\n            print(\"Information of the HPC Job Results:\")\n            print(adata)\n        else:\n            print(\"No data had returned from the HPC session. If this is not the expected behavior, please refer to the job log for further information.\")\n        return None\n\n    else:\n        NIDAP_dataset = {{{Upstream_Analysis}}}.filesystem()\n        with NIDAP_dataset.open(\"transform_output.pickle\", \"rb\") as input_file:\n            all_data = pickle.load(input_file)\n        \n        Layer_name = \"{{{Table_to_Process}}}\"\n        K_cluster = {{{K_Nearest_Neighbors}}}\n        Seed = {{{Seed}}}\n        resolution_parameter = {{{Resolution_Parameter}}}\n        output_annotation_name = \"{{{Output_Annotation_Name}}}\"\n        resolution_list = {{{Resolution_List}}}\n        n_iterations = {{{Number_of_Iterations}}}\n        ##--------------- ##\n        ## Error Messages ##\n        ## -------------- ##\n\n\n\n        ## --------- ##\n        ## Functions ##\n        ## --------- ##\n\n\n\n        ## --------------- ##\n        ## Main Code Block ##\n        ## --------------- ##\n\n        if Layer_name == \"Original\":\n            Layer_name = None\n\n        intensities = all_data.var.index.to_list()\n\n        print(\"Before Phenograph Clustering: \\n\", all_data)\n        \n        phenograph_clustering(adata=all_data, \n                            features=intensities, \n                            layer=Layer_name,\n                            k=K_cluster,\n                            seed=Seed,\n                            resolution_parameter=resolution_parameter,\n                            n_iterations=n_iterations)\n        if output_annotation_name != \"phenograph\":\n            all_data.obs = all_data.obs.rename(columns={'phenograph': output_annotation_name})\n\n\n        print(\"After Phenograph Clustering: \\n\", \n            all_data)\n\n        \n        # Count and display occurrences of each label in the annotation\n        print(f'Count of cells in the output annotation:\"{output_annotation_name}\":')\n        label_counts = all_data.obs[output_annotation_name].value_counts()\n        print(label_counts)\n        print(\"\\n\")\n        \n        \n        object_to_output = all_data\n        output = Transforms.get_output()\n        output_fs = output.filesystem()\n        with output_fs.open('transform_output.pickle', 'wb') as f:\n            pickle.dump(object_to_output, f)\n\n        return(None)\n",
      "shouldPersist": true
    }
  },
  "version": 39,
  "externalId": null,
  "canEditTemplate": true,
  "path": "/NIDAP/NCI-Wide Analysis & Visualization Resources/SPAC/SPAC Templates/Phenograph Clustering [SPAC] [DMAP]",
  "tags": [
    {
      "rid": "ri.compass.main.tag.02094a7d-d869-4dff-bc31-78ad8676d1ad",
      "name": "Code Templates:DMAP"
    },
    {
      "rid": "ri.compass.main.tag.ebb2ab0f-e354-4bd4-9f3a-e78dc8452986",
      "name": "Code Templates:SPAC"
    }
  ],
  "favorite": false,
  "namedCollections": [],
  "isDefault": true,
  "condaDependencies": [
    "python=3.6"
  ],
  "outputDatasetName": "phenograph_clustering",
  "outputs": {
    "analysis": {"type": "file", "name": "output.pickle"}
  }
}